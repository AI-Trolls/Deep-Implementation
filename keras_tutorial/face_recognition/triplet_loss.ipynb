{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet.model import create_model\n",
    "nn4_small2 = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Layer\n",
    "\n",
    "# Input for anchor, positive and negative images\n",
    "in_a = Input(shape=(96, 96, 3))\n",
    "in_p = Input(shape=(96, 96, 3))\n",
    "in_n = Input(shape=(96, 96, 3))\n",
    "\n",
    "# Output for anchor, positive and negative embedding vectors\n",
    "# The nn4_small model instance is shared (Siamese network)\n",
    "emb_a = nn4_small2(in_a)\n",
    "emb_p = nn4_small2(in_p)\n",
    "emb_n = nn4_small2(in_n)\n",
    "\n",
    "class TripletLossLayer(Layer):\n",
    "    def __init__(self, alpha, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        super(TripletLossLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def triplet_loss(self, inputs):\n",
    "        a, p, n = inputs\n",
    "        p_dist = K.sum(K.square(a-p), axis=-1)\n",
    "        n_dist = K.sum(K.square(a-n), axis=-1)\n",
    "        return K.sum(K.maximum(p_dist - n_dist + self.alpha, 0), axis=0)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        loss = self.triplet_loss(inputs)\n",
    "        self.add_loss(loss)\n",
    "        return loss\n",
    "\n",
    "# Layer that computes the triplet loss from anchor, positive and negative embedding vectors\n",
    "triplet_loss_layer = TripletLossLayer(alpha=0.2, name='triplet_loss_layer')([emb_a, emb_p, emb_n])\n",
    "\n",
    "# Model that can be trained with anchor, positive negative images\n",
    "nn4_small2_train = Model([in_a, in_p, in_n], triplet_loss_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def triplet_generator():\n",
    "    ''' Dummy triplet generator for API usage demo only.\n",
    "    Will be replaced by a version that uses real image data later.\n",
    "    :return: a batch of (anchor, positive, negative) triplets\n",
    "    '''\n",
    "    while True:\n",
    "        a_batch = np.random.rand(4, 96, 96, 3)\n",
    "        p_batch = np.random.rand(4, 96, 96, 3)\n",
    "        n_batch = np.random.rand(4, 96, 96, 3)\n",
    "        yield [a_batch , p_batch, n_batch], None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chanranhari/.local/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: Output \"triplet_loss_layer\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"triplet_loss_layer\" during training.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 36s 360ms/step - loss: 0.8014\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.8000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.7994\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.7985\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.8025\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.8002\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.8005\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.8001\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.8002\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f63162aa438>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# triplet_generator() creates a generator that continuously returns \n",
    "# ([a_batch, p_batch, n_batch], None) tuples where a_batch, p_batch \n",
    "# and n_batch are batches of anchor, positive and negative RGB images \n",
    "# each having a shape of (batch_size, 96, 96, 3).\n",
    "generator = triplet_generator() \n",
    "\n",
    "nn4_small2_train.compile(loss=None, optimizer='adam')\n",
    "nn4_small2_train.fit_generator(generator, epochs=10, steps_per_epoch=100)\n",
    "\n",
    "# Please note that the current implementation of the generator only generates \n",
    "# random image data. The main goal of this code snippet is to demonstrate \n",
    "# the general setup for model training. In the following, we will anyway \n",
    "# use a pre-trained model so we don't need a generator here that operates \n",
    "# on real training data. I'll maybe provide a fully functional generator\n",
    "# later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn4_small2_pretrained = create_model()\n",
    "nn4_small2_pretrained.load_weights('facenet/nn4.small2.v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
