{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention implementation for Dense Layer in Keras v2\n",
    "\n",
    "reference: https://github.com/philipperemy/keras-attention-mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 2\n",
    "TIME_STEPS = 20\n",
    "SINGLE_ATTENTION_VECTOR = False # if True, the attention vector is shared across the input_dimentions where the attention is applied\n",
    "APPLY_ATTENTION_BEFORE_LSTM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_stamps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    #if SINGLE_ATTENTION_VECTOR:\n",
    "    #    a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "    #    a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    # output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
    "    output_attention_mul = multiply([inputs, a_probs], name='attention_mul')\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_attention_applied_after_lstm():\n",
    "    inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))\n",
    "    lstm_units = 32\n",
    "    lstm_out = Bidirectional(GRU(lstm_units, return_sequences=True), merge_mode='concat', weights=None)(inputs)\n",
    "    attention_mul = attention_3d_block(lstm_out)\n",
    "    attention_mul = Flatten()(attention_mul)\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(inputs=[inputs], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_attention_applied_before_lstm():\n",
    "    inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))\n",
    "    attention_mul = attention_3d_block(inputs)\n",
    "    lstm_units = 32\n",
    "    attention_mul = Bidirectional(GRU(lstm_units, return_sequences=False), merge_mode='concat', weights=None)(attention_mul)\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(inputs=[inputs], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_recurrent(n, time_steps, input_dim, attention_column=10):\n",
    "    \"\"\"\n",
    "    Data generation. x is purely random except that it's first value equals the target y.\n",
    "    In practice, the network should learn that the target = x[attention_column].\n",
    "    Therefore, most of its attention should be focused on the value addressed by attention_column.\n",
    "    :param n: the number of samples to retrieve.\n",
    "    :param time_steps: the number of time steps of your series.\n",
    "    :param input_dim: the number of dimensions of each element in the series.\n",
    "    :param attention_column: the column linked to the target. Everything else is purely random.\n",
    "    :return: x: model inputs, y: model targets\n",
    "    \"\"\"\n",
    "    x = np.random.standard_normal(size=(n, time_steps, input_dim))\n",
    "    y = np.random.randint(low=0, high=2, size=(n, 1))\n",
    "    x[:, attention_column, :] = np.tile(y[:], (1, input_dim))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300000\n",
    "inputs, outputs = get_data_recurrent(N, TIME_STEPS, INPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20, 2)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 2, 20)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 2, 20)        0           permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2, 20)        420         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 20, 2)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_mul (Multiply)        (None, 20, 2)        0           input_1[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 64)           6720        attention_mul[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            65          bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 7,205\n",
      "Trainable params: 7,205\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 270000 samples, validate on 30000 samples\n",
      "Epoch 1/1\n",
      "270000/270000 [==============================] - 57s 211us/step - loss: 0.0553 - acc: 0.9696 - val_loss: 4.1553e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f18f5873438>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    if APPLY_ATTENTION_BEFORE_LSTM:\n",
    "        m = model_attention_applied_before_lstm()\n",
    "    else:\n",
    "        m = model_attention_applied_after_lstm()\n",
    "        \n",
    "    m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    print(m.summary())\n",
    "    \n",
    "    m.fit([inputs], outputs, epochs=1, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(model, inputs, print_shape_only=False, layer_name=None):\n",
    "    #print('----- activations -----')\n",
    "    activations = []\n",
    "    input_shape = model.input\n",
    "\n",
    "    if layer_name is None:\n",
    "        outputs = [layer.output for layer in model.layers]\n",
    "    else:\n",
    "        outputs = [layer.output for layer in model.layers if layer.name == layer_name] # all layer outputs\n",
    "\n",
    "    funcs = [K.function([input_shape] + [K.learning_phase()], [out]) for out in outputs] # evaluation functions\n",
    "    layer_outputs = [func([inputs, 1.])[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "        #if print_shape_only:\n",
    "        #    print(layer_activations.shape)\n",
    "        #else:\n",
    "        #print(layer_activations)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_vectors = []\n",
    "for i in range(300):\n",
    "    testing_inputs, testing_outputs = get_data_recurrent(1, TIME_STEPS, INPUT_DIM)\n",
    "    attention_vector = np.mean(get_activations(m,\n",
    "                                             testing_inputs,\n",
    "                                             print_shape_only=True,\n",
    "                                             layer_name='attention_vec')[0],\n",
    "                               axis=2).squeeze()\n",
    "    #print('attention =', attention_vector)\n",
    "    assert (np.sum(attention_vector) - 1.0) < 1e-5\n",
    "    attention_vectors.append(attention_vector)\n",
    "    \n",
    "attention_vector_final = np.mean(np.array(attention_vectors), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f18846e2128>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(attention_vector_final,\n",
    "             columns=['attention (%)']).plot(kind='bar',\n",
    "                                             title='Attention Mechanism as a function of input dimensions.',\n",
    "                                             figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
