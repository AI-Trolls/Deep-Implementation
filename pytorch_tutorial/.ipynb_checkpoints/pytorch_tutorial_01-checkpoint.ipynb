{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial\n",
    "#### A 60 Minute Blitz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is Pytorch?\n",
    "  - Tensors\n",
    "    - 텐서는 Numpy의 ndarras와 비슷한 역할.\n",
    "    - GPU의 빠른 연산을 사용하는데 이용되는 녀석."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.1345e+36,  4.5855e-41, -3.1345e+36],\n",
      "        [ 4.5855e-41,  1.4602e-19,  1.8617e+25],\n",
      "        [ 1.1835e+22,  4.3066e+21,  6.3828e+28],\n",
      "        [ 1.4603e-19,  1.1578e+27,  1.1362e+30],\n",
      "        [ 7.1547e+22,  4.5828e+30,  1.2121e+04]])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "x = torch.empty(5, 3) # 초기화되지 않은 5x3 배열을 만듬. 0이 아님을 주의!\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7245, 0.3644, 0.9418],\n",
      "        [0.3400, 0.0310, 0.3120],\n",
      "        [0.0928, 0.1340, 0.9395],\n",
      "        [0.8805, 0.6113, 0.7519],\n",
      "        [0.7671, 0.4487, 0.5750]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3) # 랜덤값으로 초기화\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long) # 0으로 초기화하고 dtype long으로 선언\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3]) # 데이터를 바로 텐서로 구성\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 0.1738, -0.3909,  0.1864],\n",
      "        [ 0.8108,  0.4802,  0.0118],\n",
      "        [-1.1652,  1.2898, -0.0017],\n",
      "        [-1.1891, -0.0711, -0.6084],\n",
      "        [-0.6715, -0.6358,  0.2645]])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor based on an existing tensor.\n",
    "\n",
    "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # dtype을 override하고 랜덤값으로 채움\n",
    "print(x)                                      # 사이즈는 동일한 것을 확인!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여기서 생긴 의문점, news_ones()와 ones()의 차이점!\n",
    "\n",
    "두 함수 모두 1로 초기화된 tensor를 생성한다. 하지만 차이점이 있다!\n",
    "\n",
    "new_ones() <br/>\n",
    ": defining the tensor along with device to run on. (Assuming CUDA hardware is available)\n",
    "    \n",
    "ones() <br/>\n",
    ": defining tensor. By default it will run on CPU.\n",
    "\n",
    "즉, ones()는 (이미 정의된, 존재하는) tensor에 의존적이지 않고, <br/>\n",
    "new_ones()는 dtype(datatype)과 device(CPU/GPU)에 대한 속성(properties)을 의존적으로 영향을 받음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rand(), randn(), rand_like(), randn_like()의 차이점!\n",
    "\n",
    "- rand()는 uniform distribution에 의해 [0, 1) 값으로 랜덤\n",
    "- randn()은 normal distrubution에 의해 mean o, variance 1로 랜덤\n",
    "- rand_like()와 randn_like()는 dtype, layout, device 값을 input의 값에 의존적\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9196, -0.1117,  0.5181],\n",
      "        [ 0.9576,  0.9618,  0.5331],\n",
      "        [-0.3924,  1.3591,  0.3203],\n",
      "        [-0.7552,  0.0927,  0.1865],\n",
      "        [-0.2099, -0.2411,  0.5027]])\n",
      "tensor([[ 0.9196, -0.1117,  0.5181],\n",
      "        [ 0.9576,  0.9618,  0.5331],\n",
      "        [-0.3924,  1.3591,  0.3203],\n",
      "        [-0.7552,  0.0927,  0.1865],\n",
      "        [-0.2099, -0.2411,  0.5027]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(torch.add(x, y))\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9196, -0.1117,  0.5181],\n",
      "        [ 0.9576,  0.9618,  0.5331],\n",
      "        [-0.3924,  1.3591,  0.3203],\n",
      "        [-0.7552,  0.0927,  0.1865],\n",
      "        [-0.2099, -0.2411,  0.5027]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result) # output tensor를 정의할 수 있음\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0935, -0.5027,  0.7045],\n",
      "        [ 1.7684,  1.4420,  0.5449],\n",
      "        [-1.5576,  2.6489,  0.3187],\n",
      "        [-1.9443,  0.0216, -0.4219],\n",
      "        [-0.8814, -0.8769,  0.7672]])\n"
     ]
    }
   ],
   "source": [
    "# adds x to y\n",
    "y.add_(x) # y값 자체를 더한 값으로 바꿔줌\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1738, -0.3909,  0.1864],\n",
      "        [ 0.8108,  0.4802,  0.0118],\n",
      "        [-1.1652,  1.2898, -0.0017],\n",
      "        [-1.1891, -0.0711, -0.6084],\n",
      "        [-0.6715, -0.6358,  0.2645]])\n",
      "tensor([-0.3909,  0.4802,  1.2898, -0.0711, -0.6358])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x[:, 1]) #2번째 열만 출력 (numpy에서와 동일한 방식이 가능함!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "tensor([[ 0.1414, -0.7787, -0.7408, -0.2906],\n",
      "        [ 0.9036,  0.3291, -0.2054, -1.5442],\n",
      "        [-0.2716,  0.3083, -0.9637,  0.9220],\n",
      "        [-0.2589,  0.0885,  0.8329,  0.4012]])\n",
      "tensor([ 0.1414, -0.7787, -0.7408, -0.2906,  0.9036,  0.3291, -0.2054, -1.5442,\n",
      "        -0.2716,  0.3083, -0.9637,  0.9220, -0.2589,  0.0885,  0.8329,  0.4012])\n",
      "tensor([[ 0.1414, -0.7787, -0.7408, -0.2906,  0.9036,  0.3291, -0.2054, -1.5442],\n",
      "        [-0.2716,  0.3083, -0.9637,  0.9220, -0.2589,  0.0885,  0.8329,  0.4012]])\n",
      "tensor([[ 0.1414, -0.7787, -0.7408, -0.2906,  0.9036,  0.3291, -0.2054, -1.5442],\n",
      "        [-0.2716,  0.3083, -0.9637,  0.9220, -0.2589,  0.0885,  0.8329,  0.4012]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions // 라는데 뭔말이징-\n",
    "z2 = x.view(2, 8)\n",
    "print(x.size(), y.size(), z.size())\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6116])\n",
      "-0.6115685105323792\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item()) #하지만 단 한개의 스칼라값에만 가능-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Numpy Array to Torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3884], device='cuda:0')\n",
      "tensor([0.3884], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
